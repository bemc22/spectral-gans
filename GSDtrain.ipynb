{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# from google.colab import drive\r\n",
    "# drive.mount('/content/drive')\r\n",
    "# import os\r\n",
    "# import sys\r\n",
    "# os.chdir('/content/drive/My Drive/ProyectoIA2/generative-spectral-datasets')"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 496,
     "status": "ok",
     "timestamp": 1618895399181,
     "user": {
      "displayName": "Brayan Monroy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkFt5R4lUgA-_UgF3sXZ-Dn_yrOMl0gC1AWiRY6Q=s64",
      "userId": "11377658055693583315"
     },
     "user_tz": 300
    },
    "id": "aBrUw_v_lUVy",
    "outputId": "eab9f534-5a8f-47dc-901a-c8fe7c76b544"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "import tensorflow as tf\r\n",
    "import numpy as np\r\n",
    "from models.main import make_autoencoder, make_discriminator\r\n",
    "\r\n",
    "\r\n",
    "input_shape = (28,28,1)"
   ],
   "outputs": [],
   "metadata": {
    "executionInfo": {
     "elapsed": 611,
     "status": "ok",
     "timestamp": 1618895416685,
     "user": {
      "displayName": "Brayan Monroy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkFt5R4lUgA-_UgF3sXZ-Dn_yrOMl0gC1AWiRY6Q=s64",
      "userId": "11377658055693583315"
     },
     "user_tz": 300
    },
    "id": "mDTG6lv5l6Mw"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\r\n",
    "\r\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\r\n",
    "train_images = train_images / 255\r\n",
    "\r\n",
    "BUFFER_SIZE = 60000\r\n",
    "BATCH_SIZE = 256\r\n",
    "\r\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\r\n",
    "mse_loss = tf.keras.losses.MeanSquaredError()\r\n",
    "\r\n",
    "\r\n",
    "def autoencoder_loss(real_x, estimated_x, real_output, fake_output):\r\n",
    "    autoencoder_loss = mse_loss(real_x, estimated_x)\r\n",
    "    gan_loss =  discriminator_loss(real_output, fake_output)\r\n",
    "    total_loss = autoencoder_loss - gan_loss\r\n",
    "    return total_loss\r\n",
    "\r\n",
    "\r\n",
    "def discriminator_loss(real_output, fake_output):\r\n",
    "    loss = tf.math.log(real_output) + tf.math.log(1 - fake_output)\r\n",
    "    return - tf.math.reduce_mean(loss)\r\n",
    "\r\n",
    "autoencoder_optimizer = tf.keras.optimizers.Adam(1e-4)\r\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\r\n",
    "\r\n",
    "\r\n",
    "autoencoder = make_autoencoder(input_shape)\r\n",
    "discriminator = make_discriminator(input_shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "@tf.function\r\n",
    "def train_step(images):\r\n",
    "\r\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\r\n",
    "      generated_images = autoencoder(images, training=True)\r\n",
    "\r\n",
    "      real_output = discriminator(images, training=True)\r\n",
    "      fake_output = discriminator(generated_images, training=True)\r\n",
    "\r\n",
    "      gen_loss = autoencoder_loss(images, generated_images, real_output, fake_output)\r\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\r\n",
    "\r\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, autoencoder.trainable_variables)\r\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\r\n",
    "\r\n",
    "    autoencoder_optimizer.apply_gradients(zip(gradients_of_generator, autoencoder.trainable_variables))\r\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\r\n",
    "\r\n",
    "\r\n",
    "def train(dataset, epochs):\r\n",
    "  print(\"START TRAINING\")\r\n",
    "  for epoch in range(epochs):\r\n",
    "    for image_batch in dataset:\r\n",
    "      train_step(image_batch)\r\n",
    "  print(\"END TRAINING\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "EPOCHS = 10\r\n",
    "\r\n",
    "\r\n",
    "train(train_dataset, EPOCHS)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO83cpy+tPP2xTzQcOLltQG",
   "collapsed_sections": [],
   "name": "GSDtrain.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('deeplearning': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "667853d8267f92520356bc341e55f361c9f9d7fd9ac7e5922db3fa10d056ae4e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}