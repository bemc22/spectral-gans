{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GSDtrain.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3.9.5 64-bit ('deeplearning': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"interpreter":{"hash":"667853d8267f92520356bc341e55f361c9f9d7fd9ac7e5922db3fa10d056ae4e"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"tmFxE1FqNhf2"},"source":["# **Deep Generative Model for spectral image synthesis**\n","* 2180034 - Brayan Esneider Monroy Chaparro\n","* 2180045 - Geison Alfredo Blanco Rodriguez\n","* 2180018 - Iván David Ortiz Pineda"]},{"cell_type":"markdown","metadata":{"id":"rTT7hz2zNh5d"},"source":["## Contextualización del problema\n","Las **imágenes espectrales** contienen la información espacial y espectral de una escena. Esta información espectral resulta muy útil en áreas como, censado remoto, medicina y agricultura. \n","\n","<center><img src=\"https://www.spaceflightinsider.com/wp-content/uploads/2014/09/phoenix-img-2.jpg\" width=\"50%\"></center>\n","\n","\n","**Justificación del problema:**\n","\n","Recientemente el Deep learning se ha incorporado entre las técnicas más prometedoras a la hora de resolver tareas de clasificación, segmentación, reconstrucción de imágenes espectrales. Sin embargo, como bien se sabe, la piedra angular del Deep learning son los datos, los cuales escasean y adicionalmente, la naturaleza de estas imágenes resulta ser de alta dimensionalidad lo cual aumenta la complejidad computacional a la hora de resolver las tareas mencionadas. \n","\n","Por consiguiente, para abordar ambas limitaciones en este trabajo se propone aprender una representación de baja dimensionalidad junto con un modelo generativo orientado a la síntesis de nuevas imágenes espectrales, permitiéndonos resolver los problemas sobre la representación de baja dimensionalidad y a su vez generar nuevos conjuntos de datos."]},{"cell_type":"markdown","metadata":{"id":"F3Bul4TwNh9F"},"source":["**Solución propuesta:**\n","\n","Un enfoque tradicional para la generación de imágenes haría uso de cierta arquitectura de red GAN (generative adversal network), en donde ingresando cierto target a la red generadora esta crearía la imagen espectral correspondiente y a través del discriminador se haría la validación sobre que tan real fue la imagen generada. Así durante el entrenamiento se buscaría aumentar la capacidad del generador para sintetizar imágenes reales.\n","\n","<center><img src=\"https://i.ibb.co/0VLnLzX/trad-1.png\" width=\"60%\"></center>"]},{"cell_type":"markdown","metadata":{"id":"_4bTUN9jNiA-"},"source":["El **enfoque propuesto** en este trabajo consiste en el uso de una metodología en dos partes:\n","* Primero, se plantea el uso de una arquitectura de red autoencoder para aprender una representación no lineal de las imágenes espectrales, a la vez que se empleará un discriminador para aprender a diferenciar las imágenes reales y falsas con el fin de mejorar la fiabilidad del autoencoder.\n","\n","<center><img src=\"https://i.ibb.co/tYYbPnM/architecture-1.png\" width=\"80%\"></center>\n","\n","* Segundo, se plantea la implementación de un algoritmo de optimización siguiendo una arquitectura de ADMM para, con los pesos previamente entrenados, poder realizar la síntesis de imágenes espectrales partiendo de imágenes a escala de grises. En esta etapa se busca específicamente el aprendizaje de la representación de baja dimensionalidad $\\alpha$ que mejor describe la imagen espectral.\n","\n","<center><img src=\"https://i.ibb.co/TBDRc41/admm-1.png\" width=\"60%\"></center>"]},{"cell_type":"markdown","metadata":{"id":"jiU3FEKENic4"},"source":["## Entrenamiento de la red utilizada"]},{"cell_type":"code","metadata":{"id":"aBrUw_v_lUVy","colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","executionInfo":{"status":"ok","timestamp":1634082002154,"user_tz":300,"elapsed":15342,"user":{"displayName":"Brayan Monroy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkFt5R4lUgA-_UgF3sXZ-Dn_yrOMl0gC1AWiRY6Q=s64","userId":"11377658055693583315"}},"outputId":"5cd1fc10-7975-4d5d-c8cf-7e6ccf3dedf5"},"source":["#@title **Código:** conexión con el drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","import sys\n","os.chdir('/content/drive/My Drive/ProyectoIA2/generative-spectral-datasets')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"mDTG6lv5l6Mw","executionInfo":{"status":"ok","timestamp":1634082012239,"user_tz":300,"elapsed":10087,"user":{"displayName":"Brayan Monroy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkFt5R4lUgA-_UgF3sXZ-Dn_yrOMl0gC1AWiRY6Q=s64","userId":"11377658055693583315"}}},"source":["#@title **Código:** importando librerías\n","\n","import tensorflow as tf\n","import numpy as np\n","from models.main import make_encoder, make_generator, make_discriminator, spectralGAN\n","from models.utils import discriminator_loss, autoencoder_loss, spec2rgb, get_RGB_matrix\n","from models.metrics import PSNR, SSIM, SAM\n","from data import load_dataset\n","import scipy.io as sio\n","import matplotlib.pyplot as plt\n","\n","input_shape = (512,512,31)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"88uBOqWQo5xn","executionInfo":{"status":"ok","timestamp":1634082012805,"user_tz":300,"elapsed":390,"user":{"displayName":"Brayan Monroy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkFt5R4lUgA-_UgF3sXZ-Dn_yrOMl0gC1AWiRY6Q=s64","userId":"11377658055693583315"}}},"source":["#@title **Código:** cargando el dataset\n","\n","BATCH_SIZE = 3\n","\n","train_params = dict(\n","    batch_size = BATCH_SIZE,\n","    shuffle = True,\n","    cache = True\n",")\n","\n","test_params = dict(\n","    batch_size = BATCH_SIZE,\n","    cache = True,\n","    shuffle = False\n",")\n","\n","train_ds , test_ds = load_dataset( train_params = train_params, test_params = test_params)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ba1SWlII-XP0","executionInfo":{"status":"ok","timestamp":1634082012805,"user_tz":300,"elapsed":2,"user":{"displayName":"Brayan Monroy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkFt5R4lUgA-_UgF3sXZ-Dn_yrOMl0gC1AWiRY6Q=s64","userId":"11377658055693583315"}}},"source":["start , stop, bands = 400, 700 , 31\n","RGB = get_RGB_matrix(start, stop, bands)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"RC7GUdjS-lFx"},"source":["sample = next(iter(train_ds))\n","im = np.expand_dims(sample[0,...], axis = 0)\n","\n","rgb = spec2rgb(im, RGB)\n","print( \"minimo\",np.min(rgb))\n","print( \"maximo\",np.max(rgb))\n","\n","plt.figure(figsize=(10,10))\n","plt.imshow(np.power(rgb[0,:,:,:], 0.5))\n","print('\\n\\n',rgb[0, 0,0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bnq50OiSo5xn"},"source":["#@title **Código:** definiendo el optimizador y arquitectura de la red\n","\n","a_optimizer = tf.keras.optimizers.Adam(1e-3)\n","d_optimizer = tf.keras.optimizers.Adam(1e-6)\n","\n","FACTOR = [ 1/8 , 1/8 , 1/4 , 1/2 , 1/2, 1]\n","features= 64\n","\n","encoded_shape = input_shape[:-1] + (3,)\n","\n","encoder = make_encoder(encoded_shape, features=features, factors=FACTOR)\n","generator = make_generator(input_shape, features=features, factors=FACTOR)\n","discriminator = make_discriminator(input_shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ElpBZh9gj5G8"},"source":["#@title **Código:** mostrando la arquitectura de las redes\n","\n","encoder.summary()\n","generator.summary()\n","discriminator.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yVWN3ifJ9PDu"},"source":["<center><img src=\"https://www.researchgate.net/profile/Gozde-Unal-2/publication/323904616/figure/fig1/AS:606457334595585@1521602104652/PatchGAN-discriminator-Each-value-of-the-output-matrix-represents-the-probability-of.png\" width=\"55%\"></center>"]},{"cell_type":"code","metadata":{"id":"I_SZC1lWdLZl"},"source":["#@title **Código:** definiendo la arquitectura\n","\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","model = spectralGAN(encoder=encoder, generator=generator, discriminator=discriminator, CMF=RGB)\n","\n","model.compile(\n","    a_optimizer = a_optimizer,\n","    d_optimizer = d_optimizer,\n","    a_loss = autoencoder_loss(tau=1e-3),\n","    d_loss = discriminator_loss,\n","    metrics = [ PSNR() , SSIM(), SAM ]\n",")\n","\n","\n","callbacks = [\n","             ModelCheckpoint( 'brayan_spectralGAN_rgb.h5', monitor='val_psnr',  verbose=1,  save_best_only=True,  save_weights_only=True,  mode=\"max\", )\n","]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LbtfoHvX-vnE"},"source":["_input = np.zeros(input_shape)[None,:]\n","\n","_ = model.__call__(_input)\n","# model.load_weights('spectralGAN.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xn39KqCCeBwU"},"source":["#@title **Código:** entrenando el modelo\n","history = model.fit(train_ds, epochs=10, validation_data=test_ds, callbacks=callbacks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RlEW7op02_5C","cellView":"form"},"source":["#@title **Código:** guardando los pesos\n","# model.save_weights('spectralGAN.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FxGWIlvnmesI"},"source":["#@title **Código:** mostrando la arquitectura general\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P8gy6peo-11L"},"source":["print(len(history.history[\"a_loss\"]))\n","plt.plot(history.history[\"a_loss\"])\n","plt.show()\n","\n","plt.plot(history.history[\"d_loss\"])\n","plt.show()\n","\n","plt.plot(history.history[\"psnr\"])\n","plt.show()\n","\n","plt.plot(history.history[\"real_acc\"])\n","plt.show()\n","\n","plt.plot(history.history[\"fake_acc\"])\n","plt.show()\n","\n","print(history.history[\"psnr\"][-1])\n","print(history.history.keys())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5u5NvxsBSCc4"},"source":["import cv2 \n","\n","nums = 3\n","\n","samples = next(iter(test_ds)).numpy()\n","_input = spec2rgb(samples, RGB)\n","generated = model.autoencoder.predict(_input)\n","generated_rgb = spec2rgb(generated, RGB)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AMUSEIIjgDwj"},"source":["#@title **Código:** mostrando imagenes generadas\n","fig, axs = plt.subplots(nums, 4, figsize=(15,12))\n","\n","_ = [ ax.axis(\"off\") for subax in axs for ax in subax]\n","\n","axs[0,0].set_title(\"Input Image\")\n","axs[0,1].set_title(\"Generated Image\")\n","axs[0,2].set_title(\"Spectral Signature P1\")\n","axs[0,3].set_title(\"Spectral Signature P2\")\n","\n","points = np.array([\n","          [200,250],\n","          [200,260],\n","          [190,190],\n","])\n","\n","points2 = np.array([\n","          [300,250],\n","          [300,120],\n","          [390,240],\n","])\n","\n","d = 8\n","\n","for i in range(nums):\n","\n","  point = points[i]\n","  point2 = points2[i]\n","\n","  x_true = np.power( tf.clip_by_value(_input[i], 0 , 1), 0.5 )\n","  x_pred = np.power( tf.clip_by_value(generated_rgb[i], 0 , 1), 0.5 )\n","\n","  x_pred = cv2.rectangle(x_pred, tuple(point - d), tuple(point + d), color=(0,255,255), thickness=3)\n","  x_pred = cv2.rectangle(x_pred, tuple(point2 - d), tuple(point2 + d), color=(255,0,255), thickness=3)\n","\n","  axs[i,0].imshow(x_true)\n","  axs[i,1].imshow(x_pred)\n","  axs[i,2].axis(\"On\")\n","  axs[i,3].axis(\"On\")\n","\n","  axs[i,2].plot( samples[i, point[1], point[0] ,:] , c='k', label=\"ground_truth\")\n","  axs[i,2].plot( generated[i, point[1], point[0] ,:] , c='r', label=\"generated\")\n","\n","\n","  axs[i,3].plot( samples[i, point2[1], point2[0] ,:] , c='k', label=\"ground_truth\")\n","  axs[i,3].plot( generated[i, point2[1], point2[0] ,:] , c='r', label=\"generated\")\n","  \n","axs[0,2].legend(loc=\"upper left\")\n","plt.show()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wbUMt0hfE-8h"},"source":[""],"execution_count":null,"outputs":[]}]}